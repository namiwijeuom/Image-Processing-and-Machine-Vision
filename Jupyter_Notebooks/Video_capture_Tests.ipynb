{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Capture and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Capture Using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video capture using opencv\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "#display the frame\n",
    "while True: \n",
    "    #Orignal frame\n",
    "    ret, frame = cap.read()\n",
    "    cv.imshow('frame', frame)\n",
    "    \n",
    "    #Convert to grayscale\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cv.imshow('gray', gray)\n",
    "\n",
    "    #Add a delay of 10ms and press q to quit\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "#Release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask for a Video Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for a video capture\n",
    "# Detecting yellow color in the video using HSV color space\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    #Orignal frame\n",
    "    #ret - return value, frame - frame\n",
    "    ret, frame = cap.read()\n",
    "    cv.imshow('frame', frame)\n",
    "    \n",
    "    #Convert to hsv\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    cv.imshow('hsv', hsv)\n",
    "\n",
    "    #lower and upper bound for the mask\n",
    "    lower_yellow = np.array([10,100,50])\n",
    "    upper_yellow = np.array([70,255,255])\n",
    "\n",
    "    #mask\n",
    "    mask = cv.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    cv.imshow('mask', mask)\n",
    "\n",
    "    #bitwise and\n",
    "    res = cv.bitwise_and(frame, frame, mask = mask)\n",
    "    cv.imshow('res', res)\n",
    "\n",
    "    #Add a delay of 10ms and press q to quit\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#Release the capture\n",
    "cap.release()   \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For an External Video Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import cv2 as cv\n",
    "\n",
    "#video capture using opencv\n",
    "cap = cv.VideoCapture(1)\n",
    "\n",
    "#display the frame\n",
    "while True: \n",
    "    #Orignal frame\n",
    "    ret, frame = cap.read()\n",
    "    cv.imshow('frame', frame)\n",
    "    \n",
    "    #Convert to grayscale\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cv.imshow('gray', gray)\n",
    "\n",
    "    #Add a delay of 10ms and press q to quit\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "#Release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Camera Feeds at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "capture_0 = cv.VideoCapture(0)\n",
    "capture_1 = cv.VideoCapture(1)\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    #Orignal frame\n",
    "    #ret - return value, frame - frame\n",
    "    _, frame_1 = capture_1.read()\n",
    "    frame_1 = cv.GaussianBlur(frame_1, (5,5), 0)\n",
    "    _, frame_0 = capture_0.read()\n",
    "    \n",
    "    # resize the frame_0\n",
    "    frame_0 = cv.resize(frame_0, (640,480))\n",
    "    cv.imshow('frame_0', frame_0)\n",
    "\n",
    "    # resize the frame_1\n",
    "    frame_1 = cv.resize(frame_1, (640,480))\n",
    "    cv.imshow('frame_1', frame_1)\n",
    "    \n",
    "    # Convert frame_0 to hsv\n",
    "    hsv = cv.cvtColor(frame_0, cv.COLOR_BGR2HSV)\n",
    "    cv.imshow('hsv_0', hsv)\n",
    "\n",
    "    # Convert frame_1 to hsv\n",
    "    hsv = cv.cvtColor(frame_1, cv.COLOR_BGR2HSV)\n",
    "    cv.imshow('hsv_1', hsv)\n",
    "\n",
    "    #lower and upper bound for the mask\n",
    "    lower_yellow = np.array([10,100,50])\n",
    "    upper_yellow = np.array([70,255,255])\n",
    "\n",
    "    #mask\n",
    "    #mask = cv.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    #cv.imshow('mask', mask)\n",
    "\n",
    "    #bitwise and\n",
    "    #res = cv.bitwise_and(frame_1, frame_1, mask = mask)\n",
    "    #cv.imshow('res', res)\n",
    "\n",
    "    #Add a delay of 10ms and press q to quit\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#Release the capture\n",
    "cap.release()   \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def read_rgb_image(image_name, show):\n",
    "    rgb_image = cv2.imread(image_name)\n",
    "    if show: \n",
    "        cv2.imshow(\"RGB Image\",rgb_image)\n",
    "    return rgb_image\n",
    "\n",
    "def filter_color(rgb_image, lower_bound_color, upper_bound_color):\n",
    "    #convert the image into the HSV color space\n",
    "    hsv_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow(\"hsv image\",hsv_image)\n",
    "\n",
    "    #find the upper and lower bounds of the yellow color (tennis ball)\n",
    "    yellowLower =(30, 150, 100)\n",
    "    yellowUpper = (50, 255, 255)\n",
    "\n",
    "    #define a mask using the lower and upper bounds of the yellow color \n",
    "    mask = cv2.inRange(hsv_image, lower_bound_color, upper_bound_color)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def getContours(binary_image):      \n",
    "    #_, contours, hierarchy = cv2.findContours(binary_image, \n",
    "    #                                          cv2.RETR_TREE, \n",
    "    #                                           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours, hierarchy = cv2.findContours(binary_image.copy(), \n",
    "                                            cv2.RETR_EXTERNAL,\n",
    "\t                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def draw_ball_contour(binary_image, rgb_image, contours):\n",
    "    black_image = np.zeros([binary_image.shape[0], binary_image.shape[1],3],'uint8')\n",
    "    \n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        perimeter= cv2.arcLength(c, True)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "        if (area>100):\n",
    "            cv2.drawContours(rgb_image, [c], -1, (150,250,150), 1)\n",
    "            cv2.drawContours(black_image, [c], -1, (150,250,150), 1)\n",
    "            cx, cy = get_contour_center(c)\n",
    "            cv2.circle(rgb_image, (cx,cy),(int)(radius),(0,0,255),1)\n",
    "            cv2.circle(black_image, (cx,cy),(int)(radius),(0,0,255),1)\n",
    "            cv2.circle(black_image, (cx,cy),5,(150,150,255),-1)\n",
    "            print (\"Area: {}, Perimeter: {}\".format(area, perimeter))\n",
    "    print (\"number of contours: {}\".format(len(contours)))\n",
    "    cv2.imshow(\"RGB Image Contours\",rgb_image)\n",
    "    cv2.imshow(\"Black Image Contours\",black_image)\n",
    "\n",
    "def get_contour_center(contour):\n",
    "    M = cv2.moments(contour)\n",
    "    cx=-1\n",
    "    cy=-1\n",
    "    if (M['m00']!=0):\n",
    "        cx= int(M['m10']/M['m00'])\n",
    "        cy= int(M['m01']/M['m00'])\n",
    "    return cx, cy\n",
    "\n",
    "def main():\n",
    "    image_name = \"C:\\Python\\ipmv\\Scripts\\Image_Processing_NoteBooks\\Images\\Tennis_Racket_and_Balls.jpg\"\n",
    "    yellowLower =(30, 150, 100)\n",
    "    yellowUpper = (50, 255, 255)\n",
    "    rgb_image = read_rgb_image(image_name, True)\n",
    "    binary_image_mask = filter_color(rgb_image, yellowLower, yellowUpper)\n",
    "    contours = getContours(binary_image_mask)\n",
    "    draw_ball_contour(binary_image_mask, rgb_image,contours)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thumbs Up Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still working on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thumbsup detectioin using a mask\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Function to detect the red ball\n",
    "def detect_red_ball(frame):\n",
    "\n",
    "    frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "    # Convert the frame from BGR to HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper HSV thresholds for red color\n",
    "    # Note: Hue range is [0, 179] and Saturation range is [0, 255] Value range is [0, 255]\n",
    "    # Need to adjust these values to detect the exact red colour of the ball\n",
    "    lower_red = np.array([0, 50, 20])\n",
    "    upper_red = np.array([30, 255, 200])\n",
    "\n",
    "    # Create a mask to extract the red regions\n",
    "    mask1 = cv2.inRange(hsv_frame, lower_red, upper_red)\n",
    "\n",
    "    # Define the lower and upper HSV thresholds for red color (shades of red)\n",
    "    lower_red = np.array([160, 100, 100])\n",
    "    upper_red = np.array([179, 255, 255])\n",
    "\n",
    "    # Create another mask to extract the red regions (shades of red)\n",
    "    mask2 = cv2.inRange(hsv_frame, lower_red, upper_red)\n",
    "\n",
    "    # Combine the two masks to get the final mask for red regions\n",
    "    red_mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Apply the mask to the original frame\n",
    "    red_ball = cv2.bitwise_and(frame, frame, mask=red_mask)\n",
    "    #red_ball = cv2.bitwise_and(frame, frame, mask=mask1)\n",
    "\n",
    "    # draw a circle around all the red balls in the frame\n",
    "    contours, hierarchy = cv2.findContours(red_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #contours, hierarchy = cv2.findContours(mask1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    area_array=[]\n",
    "    for contour in contours:\n",
    "        #area = cv2.contourArea(contour)\n",
    "        perimeter= cv2.arcLength(contour, True)\n",
    "\n",
    "        if 400 < perimeter < 800: #can adjust this value with the area of the red ball\n",
    "        #if 100< area < 200: #can adjust this value with the area of the red ball\n",
    "            #area_array.append(area)\n",
    "            area_array.append(perimeter)    \n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.circle(red_ball, (int(x + w/2), int(y + h/2)), int((w + h)/4), (0, 255, 0), 2)\n",
    "    \n",
    "    # display the number of red balls in the frame with area greater than 500\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(red_ball, 'Number of red balls: ' + str(len(area_array)), (10, 50), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return red_ball\n",
    "\n",
    "\n",
    "# Open a video capture object or use the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video source\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect the red ball in the frame\n",
    "    red_ball = detect_red_ball(frame)\n",
    "\n",
    "    # Display the original frame and the red ball detection\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Red Ball Detection', red_ball)\n",
    "\n",
    "    # Exit when the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic()\n",
    "\n",
    "# Initialize MediaPipe Drawing\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open a video capture\n",
    "cap = cv2.VideoCapture(0)  # Use the default camera (change the parameter if using an external camera)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for a later selfie-view display\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame to detect gestures\n",
    "    results = holistic.process(frame_rgb)\n",
    "\n",
    "    if results.pose_landmarks and results.left_hand_landmarks:\n",
    "        left_hand_landmarks = results.left_hand_landmarks.landmark\n",
    "\n",
    "        # Assuming that the thumb and index finger landmarks are detected correctly\n",
    "        thumb_tip = left_hand_landmarks[4]\n",
    "        index_tip = left_hand_landmarks[8]\n",
    "\n",
    "        # Calculate the Euclidean distance between thumb and index finger tips\n",
    "        distance = ((thumb_tip.x - index_tip.x) ** 2 + (thumb_tip.y - index_tip.y) ** 2) ** 0.5\n",
    "\n",
    "        # Adjust this threshold to define when a thumbs-up is detected\n",
    "        if distance < 0.05:\n",
    "            cv2.putText(frame, \"Thumbs Up\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Draw hand landmarks on the frame\n",
    "    mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Thumbs-Up Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "capture_0 = cv.VideoCapture(0)\n",
    "capture_1 = cv.VideoCapture(1)\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    #Orignal frame\n",
    "    #ret - return value, frame - frame\n",
    "    _, frame_1 = capture_1.read()\n",
    "    frame_1 = cv.GaussianBlur(frame_1, (5,5), 0)\n",
    "    _, frame_0 = capture_0.read()\n",
    "    \n",
    "    # resize the frame_0\n",
    "    frame_0 = cv.resize(frame_0, (640,480))\n",
    "    cv.imshow('frame_0', frame_0)\n",
    "\n",
    "    # resize the frame_1\n",
    "    frame_1 = cv.resize(frame_1, (640,480))\n",
    "    cv.imshow('frame_1', frame_1)\n",
    "    \n",
    "    # Convert frame_0 to hsv\n",
    "    hsv = cv.cvtColor(frame_0, cv.COLOR_BGR2HSV)\n",
    "    cv.imshow('hsv_0', hsv)\n",
    "\n",
    "    # Convert frame_1 to hsv\n",
    "    hsv = cv.cvtColor(frame_1, cv.COLOR_BGR2HSV)\n",
    "    cv.imshow('hsv_1', hsv)\n",
    "\n",
    "    #lower and upper bound for the mask\n",
    "    lower_yellow = np.array([10,100,50])\n",
    "    upper_yellow = np.array([70,255,255])\n",
    "\n",
    "    #mask\n",
    "    #mask = cv.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    #cv.imshow('mask', mask)\n",
    "\n",
    "    #bitwise and\n",
    "    #res = cv.bitwise_and(frame_1, frame_1, mask = mask)\n",
    "    #cv.imshow('res', res)\n",
    "\n",
    "    #Add a delay of 10ms and press q to quit\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#Release the capture\n",
    "cap.release()   \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth of the Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried with my webcamera and mobile phone camera. They don't give a correct result at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the video capture with the appropriate source (e.g., 0 for the default camera).\n",
    "cap_i = cv2.VideoCapture(0)  # IRIUN camera.\n",
    "cap_f = cv2.VideoCapture(1)  # Default camera.\n",
    "\n",
    "while True:\n",
    "    ret_i, depth_frame_i = cap_i.read()  # Read a depth frame.\n",
    "    ret_f, depth_frame_f = cap_f.read()  # Read a depth frame.\n",
    "\n",
    "    depth_frame_i_gray = cv2.cvtColor(depth_frame_i, cv2.COLOR_BGR2GRAY)\n",
    "    depth_frame_f_gray = cv2.cvtColor(depth_frame_f, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    stereo = cv2.StereoBM.create(numDisparities=16, blockSize=15)\n",
    "    disparity = stereo.compute(depth_frame_f_gray,depth_frame_i_gray)\n",
    "\n",
    "    # Display the depth frame and its colormap.\n",
    "    cv2.imshow('IRIUN Camera', depth_frame_i)\n",
    "    cv2.imshow('Front Web Camera', depth_frame_f)\n",
    "    cv2.imshow('Disparity', disparity)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
